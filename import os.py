import os
os.makedirs("E:\\huggingface_cache", exist_ok=True)
os.environ["HF_HOME"] = "E:\\huggingface_cache"
import tkinter as tk
import pandas as pd
import matplotlib.pyplot as plt
import random
import json
import re

# ----------------------------
# ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ø°Ø®ÛŒØ±Ù‡â€ŒØ³Ø§Ø²ÛŒ
# ----------------------------
history_file = "sentiment_history.csv"
memory_file = "conversation_memory.json"

# Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ÛŒØ§ Ø§ÛŒØ¬Ø§Ø¯ ÙØ§ÛŒÙ„ ØªØ§Ø±ÛŒØ®Ú†Ù‡
try:
    df = pd.read_csv(history_file)
except FileNotFoundError:
    df = pd.DataFrame(columns=["Text", "Emotion", "Response"])
    df.to_csv(history_file, index=False)

# Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ÛŒØ§ Ø§ÛŒØ¬Ø§Ø¯ Ø­Ø§ÙØ¸Ù‡ Ù…Ú©Ø§Ù„Ù…Ù‡
try:
    with open(memory_file, "r", encoding="utf-8") as f:
        conversation_memory = json.load(f)
except (FileNotFoundError, json.JSONDecodeError):
    conversation_memory = []

# ----------------------------
# Ø±Ù†Ú¯â€ŒÙ‡Ø§ Ø¨Ø±Ø§ÛŒ Ø§Ø­Ø³Ø§Ø³Ø§Øª
# ----------------------------
color_map = {
    "Ø®ÙˆØ´Ø­Ø§Ù„": "#A3E4D7",
    "Ù†Ø§Ø±Ø§Ø­Øª": "#F1948A",
    "Ø¹ØµØ¨ÛŒ": "#F7DC6F",
    "Ø®Ù†Ø«ÛŒ": "#D7DBDD"
}

# ----------------------------
# Ù†Ú¯Ø§Ø´Øª Ø§Ø­Ø³Ø§Ø³Ø§Øª Ø¨Ø±Ø§ÛŒ Ù†Ù…ÙˆØ¯Ø§Ø±
# ----------------------------
emotion_to_english = {
    "Ø®ÙˆØ´Ø­Ø§Ù„": "Happy",
    "Ù†Ø§Ø±Ø§Ø­Øª": "Sad",
    "Ø¹ØµØ¨ÛŒ": "Angry",
    "Ø®Ù†Ø«ÛŒ": "Neutral"
}

# ----------------------------
# ØªØ´Ø®ÛŒØµ Ø§Ø­Ø³Ø§Ø³Ø§Øª
# ----------------------------

def get_emotion(text):
    text_lower = text.lower()

    # --------------------
    # Ú©Ù„Ù…Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ ÙØ§Ø±Ø³ÛŒ
    # --------------------
    positive_words_fa = ["Ø®ÙˆØ´", "Ø´Ø§Ø¯", "Ø¹Ø§Ù„ÛŒ", "Ø®ÙˆØ¨", "Ø´Ø§Ø¯ÛŒ", "Ù„Ø°Øª", "Ø²ÛŒØ¨Ø§", "Ø®ÙˆØ´Ø­Ø§Ù„","Ø®ÙˆØ´Ø¨Ø®Øª","Ø±Ø§Ø¶ÛŒ","Ø­Ø§Ù„ Ø®ÙˆØ¨","Ø³Ø±Ø­Ø§Ù„","Ù¾Ø±Ø§Ù†Ø±Ú˜ÛŒ",]
    negative_words_fa = ["Ù†Ø§Ø±Ø§Ø­Øª", "ØºÙ…Ú¯ÛŒÙ†", "Ø¨Ø¯", "ØºÙ…", "Ø§Ø´ØªØ¨Ø§Ù‡", "Ø¯Ø±Ø¯", "Ù…Ø´Ú©Ù„", "Ú©Ù„Ø§ÙÙ‡","Ø®Ø³ØªÙ‡","Ù†Ø§Ø§Ù…ÛŒØ¯","Ù†Ø§Ø§Ù…ÛŒØ¯ Ø§Ù…","Ø¯Ù„Ø®ÙˆØ±","Ø³ÙˆÚ¯ÙˆØ§Ø±","Ù¾Ø±ÛŒØ´ÙˆÙ†","Ø¨ÛŒ Ø­ÙˆØµÙ„Ù‡"]
    angry_words_fa = ["Ø¹ØµØ¨Ø§Ù†ÛŒ", "Ø®Ø´Ù…", "Ø§Ø¹ØµØ§Ø¨", "Ø­Ø±Øµ", "Ø¹ØµØ¨Ø§Ù†ÛŒØª", "Ù†Ø§Ø±Ø§Ø­ØªÛŒ","Ø¹ØµØ¨","Ø¹ØµØ¨Ø§Ù†ÛŒ ØªØ±","Ø§Ø¹ØµØ§Ø¨","Ø®Ø´Ù…Ú¯ÛŒÙ†","Ø§Ù†ØªÙ‚Ø§Ù…","Ù†ÙØ±Øª","Ø¯Ù„Ø®ÙˆØ±","Ø´Ø¯ÛŒØ¯ Ø¹ØµØ¨Ø§Ù†ÛŒ","Ø§Ø´ÙØªÙ‡","Ø±Ø¯ Ø¯Ø§Ø¯Ù…",]

    # --------------------
    # Ú©Ù„Ù…Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ
    # --------------------
    positive_words_en = ["happy", "good", "great", "joy", "glad", "awesome", "thankful", "love"]
    negative_words_en = ["sad", "bad", "unhappy", "angry", "pain", "problem", "upset", "frustrated"]
    angry_words_en = ["angry", "furious", "mad", "irritated", "annoyed"]

    # --------------------
    # Ø§Ù†ØªØ®Ø§Ø¨ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø²Ø¨Ø§Ù†
    # --------------------
    if is_persian(text):
        positive_words = positive_words_fa
        negative_words = negative_words_fa
        angry_words = angry_words_fa
    else:
        positive_words = positive_words_en
        negative_words = negative_words_en
        angry_words = angry_words_en

    # --------------------
    # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø§Ù…ØªÛŒØ§Ø² Ø§Ø­Ø³Ø§Ø³
    # --------------------
      # Ø§Ù…ØªÛŒØ§Ø²Ø¯Ù‡ÛŒ Ø¬Ø¯Ø§Ú¯Ø§Ù†Ù‡
    pos_count = sum(word in text_lower for word in positive_words)
    neg_count = sum(word in text_lower for word in negative_words)
    angry_count = sum(word in text_lower for word in angry_words)

    # --------------------
    # ØªØµÙ…ÛŒÙ…â€ŒÚ¯ÛŒØ±ÛŒ Ù†Ù‡Ø§ÛŒÛŒ
    # --------------------
      # ØªØµÙ…ÛŒÙ…â€ŒÚ¯ÛŒØ±ÛŒ
    if angry_count > 0:
        return "Ø¹ØµØ¨ÛŒ"
    elif neg_count > 0:
        return "Ù†Ø§Ø±Ø§Ø­Øª"
    elif pos_count > 0:
        return "Ø®ÙˆØ´Ø­Ø§Ù„"
    else:
        return "Ø®Ù†Ø«ÛŒ"
# ----------------------------
# ØªØ´Ø®ÛŒØµ ÙØ§Ø±Ø³ÛŒ
# ----------------------------
def is_persian(text):
    return any('\u0600' <= ch <= '\u06FF' for ch in text)

# ----------------------------
# Ù¾Ø§Ø³Ø®â€ŒÙ‡Ø§ÛŒ Ù…Ø­Ø§ÙˆØ±Ù‡â€ŒØ§ÛŒ
# ----------------------------
responses_dict_fa = {
    "Ø®ÙˆØ´Ø­Ø§Ù„": {
        "starts": ["ğŸ˜Š  Ú†Ù‡ Ø¹Ø§Ù„ÛŒ!Ø±ÙÛŒÙ‚", "ğŸ˜ƒ Ø®ÙˆØ´Ø­Ø§Ù„Ù… Ø¨Ø±Ø§Øª!Ø§ÛŒ Ø¬Ø§Ù†", "ğŸ‘ Ø§Ù…Ø±ÙˆØ² ÙÙˆÙ‚â€ŒØ§Ù„Ø¹Ø§Ø¯Ù‡â€ŒØ³Øª!Ø¨Ø±Ø§ÛŒ ØªÙˆ", "ğŸŒŸ Ø®Ø¨Ø± Ø®ÙˆØ¨ÛŒÙ‡!"],
        "ends": ["Ø±ÙˆØ²Øª Ø¹Ø§Ù„ÛŒ Ø¨Ø§Ø´Ù‡!", "Ø§ÛŒÙ† Ø§Ù†Ø±Ú˜ÛŒ Ù…Ø«Ø¨Øª Ø§Ø¯Ø§Ù…Ù‡ Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´Ù‡!", "Ù„Ø°Øª Ø¨Ø¨Ø±!", "Ù‡Ù…ÛŒØ´Ù‡ Ø®ÙˆØ´Ø­Ø§Ù„ Ø¨Ø§Ø´ÛŒ!"]
    },
    "Ù†Ø§Ø±Ø§Ø­Øª": {
        "starts": ["ğŸ’› Ù†Ú¯Ø±Ø§Ù† Ù†Ø¨Ø§Ø´ØŒ Ù‡Ù…Ù‡ Ú†ÛŒØ² Ø¯Ø±Ø³Øª Ù…ÛŒØ´Ù‡.", "ğŸ’ª Ù…Ù† Ú©Ù†Ø§Ø±ØªÙ….", "ğŸ˜” Ù…ÛŒâ€ŒÙÙ‡Ù…Ù… Ø­Ø§Ù„Øª Ø±Ùˆ.", "ğŸ˜¢ Ù…ÛŒâ€ŒØ¯ÙˆÙ†Ù… Ù†Ø§Ø±Ø§Ø­ØªÛŒ.","Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ Ù…ÛŒÚ©Ù†Ù… ÛŒÙ‡ Ù…Ø¯ÛŒØªÛŒØ´Ù† Ú©Ù†ÛŒ Ø±ÙÛŒÙ‚ .",
                   "ØªÙˆ Ø®ÛŒÙ„ÛŒ Ù‚ÙˆÛŒ ØªØ± Ø§Ø² Ø§ÛŒÙ† Ø­Ø±ÙØ§ÛŒÛŒ Ù‡Ø§ Ù…ÛŒØ¯ÙˆÙ†Ø³ØªÛŒØŸ" ],
        "ends": ["Ù‡Ù…Ù‡ Ú†ÛŒØ² Ø¨Ù‡ØªØ± Ù…ÛŒØ´Ù‡.", "Ø³Ø¹ÛŒ Ú©Ù† Ú©Ù…ÛŒ Ø§Ø³ØªØ±Ø§Ø­Øª Ú©Ù†ÛŒ.", "Ù…Ù† Ø§ÛŒÙ†Ø¬Ø§Ù… Ú©Ù†Ø§Ø±Øª.", "Ù‚ÙˆÛŒ Ø¨Ø§Ø´."]
    },
    "Ø¹ØµØ¨ÛŒ": {
        "starts": ["ğŸ§˜â€â™‚ ÛŒÙ‡ Ù†ÙØ³ Ø¹Ù…ÛŒÙ‚ Ø¨Ú©Ø´.", "ğŸ•Š Ø³Ø¹ÛŒ Ú©Ù† Ø¢Ø±ÙˆÙ… Ø¨Ø§Ø´ÛŒ.", "ğŸ˜¤ Ù…ÛŒâ€ŒÙÙ‡Ù…Ù… Ø­Ø§Ù„Øª Ø±Ùˆ.", "ğŸ’†â€â™‚ Ú©Ù…ÛŒ Ø§Ø³ØªØ±Ø§Ø­Øª Ú©Ù†."],
        "ends": ["Ø­ÙˆØ§Ø³Øª Ø¨Ù‡ Ø®ÙˆØ¯Øª Ø¨Ø§Ø´Ù‡.", "Ø¨Ù‡ Ø®ÙˆØ¯Øª ÙØ´Ø§Ø± Ù†ÛŒØ§Ø±.", "Ù‡Ù…Ù‡ Ú†ÛŒ Ø¯Ø±Ø³Øª Ù…ÛŒØ´Ù‡.", "ÛŒÙ‡ Ù„Ø­Ø¸Ù‡ Ø¢Ø±Ø§Ù… Ø¨Ø§Ø´.","Ø¯Ø±Ú©Øª Ù…ÛŒÚ©Ù†Ù… Ø±ÙÛŒÙ‚ Ù…Ù† Ú©Ù†Ø§Ø±ØªÙ…."
                 ,"Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ Ù…ÛŒÚ©Ù†Ù… ÛŒÙ‡ Ù…Ø¯ÛŒØªÛŒØ´Ù† Ú©Ù†ÛŒ Ø±ÙÛŒÙ‚ .","ØªÙˆ Ø®ÛŒÙ„ÛŒ Ù‚ÙˆÛŒ ØªØ± Ø§Ø² Ø§ÛŒÙ† Ø­Ø±ÙØ§ÛŒÛŒ Ù‡Ø§ Ù…ÛŒØ¯ÙˆÙ†Ø³ØªÛŒØŸ"]
    },
    "Ø®Ù†Ø«ÛŒ": {
        "starts": ["ğŸ˜ ÙÙ‡Ù…ÛŒØ¯Ù….", "ğŸ¤” Ù…ØªÙˆØ¬Ù‡ Ø´Ø¯Ù….", "ğŸ™‚ Ø®Ø¨.", "ğŸ˜¶ Ø§ÙˆÚ©ÛŒ."],
        "ends": ["Ø§Ø¯Ø§Ù…Ù‡ Ø¨Ø¯Ù‡.", "Ù…ØªÙˆØ¬Ù‡ Ø´Ø¯Ù….", "Ø§ÙˆÚ©ÛŒØŒ Ø¨Ø§Ø´Ù‡.", "ÙÙ‡Ù…ÛŒØ¯Ù…."]
    }
}

responses_dict_en = {
    "Ø®ÙˆØ´Ø­Ø§Ù„": {
        "starts": ["ğŸ˜Š That's great!", "ğŸ˜ƒ I'm happy for you!", "ğŸ‘ Awesome!", "ğŸŒŸ Good news!"],
        "ends": ["Have a wonderful day!", "Keep this positive energy!", "Enjoy!", "Stay happy!"]
    },
    "Ù†Ø§Ø±Ø§Ø­Øª": {
        "starts": ["ğŸ’› Don't worry, it'll get better.", "ğŸ’ª I'm here for you.", "ğŸ˜” I understand how you feel.", "ğŸ˜¢ I know it's tough."],
        "ends": ["Everything will improve.", "Try to take a break.", "I'm here with you.", "Stay strong."]
    },
    "Ø¹ØµØ¨ÛŒ": {
        "starts": ["ğŸ§˜â€â™‚ Take a deep breath.", "ğŸ•Š Try to stay calm.", "ğŸ˜¤ I get it, you're frustrated.", "ğŸ’†â€â™‚ Take a short rest."],
        "ends": ["Take care of yourself.", "Don't pressure yourself.", "Everything will be fine.", "Relax for a moment."]
    },
    "Ø®Ù†Ø«ÛŒ": {
        "starts": ["ğŸ˜ I see.", "ğŸ¤” Got it.", "ğŸ™‚ Okay.", "ğŸ˜¶ Alright."],
        "ends": ["Carry on.", "Understood.", "Okay then.", "Noted."]
    }
}

# ----------------------------
# ØªÙˆÙ„ÛŒØ¯ Ù¾Ø§Ø³Ø® Ù…Ø­Ø§ÙˆØ±Ù‡â€ŒØ§ÛŒ
# ----------------------------
def generate_response(user_input):
    try:
        emotion = get_emotion(user_input)
        
        if is_persian(user_input):
            parts = responses_dict_fa[emotion]
        else:
            parts = responses_dict_en[emotion]
        
        start = random.choice(parts["starts"])
        end = random.choice(parts["ends"])
        
        response_text = f"{start} {end}".strip()
        return response_text
    except Exception as e:
        return f"Ø®Ø·Ø§ Ø¯Ø± ØªÙˆÙ„ÛŒØ¯ Ù¾Ø§Ø³Ø®: {e}"

# ----------------------------
# ØªØ´Ø®ÛŒØµ Ø§Ø­Ø³Ø§Ø³ Ùˆ Ù†Ù…Ø§ÛŒØ´ Ù¾Ø§Ø³Ø®
# ----------------------------
def detect_sentiment():
    try:
        user_text = text_entry.get().strip()
        if not user_text:
            return

        text_entry.delete(0, tk.END)

        emotion = get_emotion(user_text)
        response_text = generate_response(user_text)

        conversation_text.insert(tk.END, f"Ø´Ù…Ø§: {user_text}\n")
        conversation_text.insert(tk.END, f"Ú†Øªâ€ŒØ¨Ø§Øª: {response_text}\n\n")
        conversation_text.see(tk.END)

        # Ø±Ù†Ú¯ Ù¾Ø³â€ŒØ²Ù…ÛŒÙ†Ù‡ Ø¨Ø±Ø§ÛŒ ÙØ§Ø±Ø³ÛŒ
        if is_persian(user_text):
            root.config(bg=color_map.get(emotion, "#D7DBDD"))
        else:
            root.config(bg="#D7DBDD")

        global df
        df = pd.concat([df, pd.DataFrame({"Text": [user_text], "Emotion": [emotion], "Response": [response_text]})], ignore_index=True)

    except Exception as e:
        conversation_text.insert(tk.END, f"Ø®Ø·Ø§: {str(e)}\n\n")
        print(f"Error in detect_sentiment: {e}")

# ----------------------------
# Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø¯Ø± Ø²Ù…Ø§Ù† Ø®Ø±ÙˆØ¬
# ----------------------------
def save_data_on_exit():
    try:
        df.to_csv(history_file, index=False)
        with open(memory_file, "w", encoding="utf-8") as f:
            json.dump(conversation_memory, f, ensure_ascii=False, indent=2)
    except Exception as e:
        print(f"Error saving data: {e}")

# ----------------------------
# Ù†Ù…ÙˆØ¯Ø§Ø± Ø§Ø­Ø³Ø§Ø³Ø§Øª
# ----------------------------
def show_chart():
    try:
        if df.empty:
            conversation_text.insert(tk.END, "No data available to display the chart.\n\n")
            return
        counts = df['Emotion'].map(emotion_to_english).value_counts()
        counts.plot(kind='bar', color=[color_map.get(e, '#D7DBDD') for e in df['Emotion']])
        plt.title("Sentiment Distribution")
        plt.ylabel("Count")
        plt.xlabel("Sentiment")
        plt.show()
    except Exception as e:
        conversation_text.insert(tk.END, f"Error displaying chart: {str(e)}\n\n")
        print(f"Error in show_chart: {e}")

# ----------------------------
# GUI
# ----------------------------
root = tk.Tk()
root.title("Ú†Øªâ€ŒØ¨Ø§Øª ÙØ§Ø±Ø³ÛŒ Ùˆ Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ")
root.geometry("700x600")
root.config(bg="#D7DBDD")

tk.Label(root, text="Ø¬Ù…Ù„Ù‡ Ø®ÙˆØ¯ Ø±Ø§ ÙˆØ§Ø±Ø¯ Ú©Ù†ÛŒØ¯ (ÙØ§Ø±Ø³ÛŒ ÛŒØ§ Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ):", bg="#D7DBDD", font=("Arial", 12)).pack(pady=5)

text_entry = tk.Entry(root, width=85, font=("Arial", 10))
text_entry.pack(pady=5)
root.bind('<Return>', lambda event: detect_sentiment())

tk.Button(root, text="Ø§Ø±Ø³Ø§Ù„ Ø¬Ù…Ù„Ù‡ Ùˆ Ø¯Ø±ÛŒØ§ÙØª Ù¾Ø§Ø³Ø®", command=detect_sentiment, font=("Arial", 10)).pack(pady=5)
tk.Button(root, text="Ù†Ù…Ø§ÛŒØ´ Ù†Ù…ÙˆØ¯Ø§Ø± Ø§Ø­Ø³Ø§Ø³Ø§Øª", command=show_chart, font=("Arial", 10)).pack(pady=5)

conversation_text = tk.Text(root, width=85, height=25, font=("Arial", 10))
conversation_text.pack(pady=5)

root.protocol("WM_DELETE_WINDOW", save_data_on_exit)

print("Ø¨Ø±Ù†Ø§Ù…Ù‡ Ø¢Ù…Ø§Ø¯Ù‡ Ø§Ø¬Ø±Ø§ Ø§Ø³Øª.")
root.mainloop()
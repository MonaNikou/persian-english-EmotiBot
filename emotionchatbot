import os
import tkinter as tk
from transformers import AutoModelForCausalLM, AutoTokenizer
import torch
import pandas as pd
import matplotlib.pyplot as plt
import pyttsx3
import random
import threading
import json

# ----------------------------
# ØªØºÛŒÛŒØ± Ù…Ø³ÛŒØ± Hugging Face Ø¨Ù‡ Ø¯Ø±Ø§ÛŒÙˆ E
# ----------------------------
os.environ["HF_HOME"] = "E:\\huggingface_cache"

# ----------------------------
# Ù…ÙˆØªÙˆØ± ØµØ¯Ø§
# ----------------------------
engine = pyttsx3.init()
engine.setProperty('rate', 150)
engine.setProperty('volume', 1.0)

# ----------------------------
# ÙØ§ÛŒÙ„ CSV Ùˆ JSON
# ----------------------------
history_file = "sentiment_history.csv"
memory_file = "conversation_memory.json"

try:
    df = pd.read_csv(history_file)
except FileNotFoundError:
    df = pd.DataFrame(columns=["Text", "Emotion", "Response"])
    df.to_csv(history_file, index=False)

if os.path.exists(memory_file):
    with open(memory_file, "r", encoding="utf-8") as f:
        conversation_memory = json.load(f)
else:
    conversation_memory = []

# ----------------------------
# Ø±Ù†Ú¯â€ŒÙ‡Ø§ Ùˆ Ù¾Ø§Ø³Ø®â€ŒÙ‡Ø§ÛŒ Ù¾Ø§ÛŒÙ‡
# ----------------------------
color_map = {
    "Ø®ÙˆØ´Ø­Ø§Ù„": "#A3E4D7",
    "Ù†Ø§Ø±Ø§Ø­Øª": "#F1948A",
    "Ø¹ØµØ¨Ø§Ù†ÛŒ": "#F7DC6F",
    "Ø®Ù†Ø«ÛŒ": "#D7DBDD"
}

responses_prefix = {
    "Ø®ÙˆØ´Ø­Ø§Ù„": ["ğŸ˜Š Ø¢ÙØ±ÛŒÙ†! ", "ğŸ˜ƒ Ú†Ù‡ Ø®ÙˆØ¨! "],
    "Ù†Ø§Ø±Ø§Ø­Øª": ["ğŸ’› Ù†Ú¯Ø±Ø§Ù† Ù†Ø¨Ø§Ø´ØŒ ", "ğŸ’ª Ù‡Ù…Ù‡ Ù…Ø§ Ø±ÙˆØ²Ù‡Ø§ÛŒ Ø³Ø®Øª Ø¯Ø§Ø±ÛŒÙ…ØŒ "],
    "Ø¹ØµØ¨Ø§Ù†ÛŒ": ["ğŸ§˜â€â™‚ Ø¢Ø±Ø§Ù… Ø¨Ø§Ø´ØŒ ", "ğŸ•Š Ú©Ù…ÛŒ Ø§Ø³ØªØ±Ø§Ø­Øª Ú©Ù†ØŒ "],
    "Ø®Ù†Ø«ÛŒ": ["ğŸ˜ ", "ğŸ¤” "]
}

# ----------------------------
# Ù…Ø¯Ù„ Ú†Øª Ù‡ÙˆØ´Ù…Ù†Ø¯ DialoGPT-Small
# ----------------------------
tokenizer = AutoTokenizer.from_pretrained("microsoft/DialoGPT-small")
model = AutoModelForCausalLM.from_pretrained("microsoft/DialoGPT-small")

# ----------------------------
# ØªØ­Ù„ÛŒÙ„ Ø§Ø­Ø³Ø§Ø³Ø§Øª Ø³Ø§Ø¯Ù‡ Ø¨Ø§ Ú©Ù„ÛŒØ¯ÙˆØ§Ú˜Ù‡
# ----------------------------
def get_emotion(text):
    text_lower = text.lower()
    if any(w in text_lower for w in ["Ø®ÙˆØ´", "Ø´Ø§Ø¯", "Ø¹Ø§Ù„ÛŒ", "Ø®ÙˆØ´Ø­Ø§Ù„"]):
        return "Ø®ÙˆØ´Ø­Ø§Ù„"
    elif any(w in text_lower for w in ["Ù†Ø§Ø±Ø§Ø­Øª", "ØºÙ…Ú¯ÛŒÙ†", "Ø¨Ø¯", "ØºÙ…"]):
        return "Ù†Ø§Ø±Ø§Ø­Øª"
    elif any(w in text_lower for w in ["Ø¹ØµØ¨Ø§Ù†ÛŒ", "Ø®Ø´Ù…", "Ø§Ø¹ØµØ§Ø¨"]):
        return "Ø¹ØµØ¨ÛŒ"
    else:
        return "Ø®Ù†Ø«ÛŒ"

# ----------------------------
# ØµØ¯Ø§
# ----------------------------
def speak(text):
    engine.say(text)
    engine.runAndWait()

# ----------------------------
# ØªÙˆÙ„ÛŒØ¯ Ù¾Ø§Ø³Ø® Ù‡ÙˆØ´Ù…Ù†Ø¯
# ----------------------------
def generate_response(user_input):
    conversation_memory.append({"role": "user", "text": user_input})

    context_text = ""
    for msg in conversation_memory[-6:]:
        role = "User" if msg['role']=="user" else "Bot"
        context_text += f"{role}: {msg['text']}\n"

    inputs = tokenizer.encode(context_text + tokenizer.eos_token, return_tensors="pt")
    outputs = model.generate(inputs, max_length=200, pad_token_id=tokenizer.eos_token_id)
    response = tokenizer.decode(outputs[:, inputs.shape[-1]:][0], skip_special_tokens=True)

    conversation_memory.append({"role": "bot", "text": response})

    with open(memory_file, "w", encoding="utf-8") as f:
        json.dump(conversation_memory, f, ensure_ascii=False, indent=2)

    return response

# ----------------------------
# ØªØ´Ø®ÛŒØµ Ø§Ø­Ø³Ø§Ø³ Ùˆ Ù†Ù…Ø§ÛŒØ´ Ù¾Ø§Ø³Ø®
# ----------------------------
def detect_sentiment():
    user_text = text_entry.get().strip()
    if not user_text:
        return

    text_entry.delete(0, tk.END)

    emotion = get_emotion(user_text)
    response_text = generate_response(user_text)
    response_text = random.choice(responses_prefix[emotion]) + response_text

    conversation_text.insert(tk.END, f"Ø´Ù…Ø§: {user_text}\n")
    conversation_text.insert(tk.END, f"Ú†Øªâ€ŒØ¨Ø§Øª: {response_text}\n\n")
    conversation_text.see(tk.END)

    root.config(bg=color_map.get(emotion, "#FFFFFF"))

    threading.Thread(target=speak, args=(f"Ø§Ø­Ø³Ø§Ø³ Ø¬Ù…Ù„Ù‡ Ø´Ù…Ø§ {emotion} Ø§Ø³Øª. {response_text}",)).start()

    global df
    df = pd.concat([df, pd.DataFrame({"Text":[user_text], "Emotion":[emotion], "Response":[response_text]})], ignore_index=True)
    df.to_csv(history_file, index=False)

# ----------------------------
# Ù†Ù…ÙˆØ¯Ø§Ø± Ø§Ø­Ø³Ø§Ø³Ø§Øª
# ----------------------------
def show_chart():
    if df.empty:
        return
    counts = df['Emotion'].value_counts()
    counts.plot(kind='bar', color=['#A3E4D7','#F1948A','#F7DC6F','#D7DBDD'])
    plt.title("Ù†Ù…ÙˆØ¯Ø§Ø± Ø§Ø­Ø³Ø§Ø³Ø§Øª")
    plt.ylabel("ØªØ¹Ø¯Ø§Ø¯")
    plt.show()

# ----------------------------
# GUI
# ----------------------------
root = tk.Tk()
root.title("Ú†Øªâ€ŒØ¨Ø§Øª Ø±Ø§ÛŒÚ¯Ø§Ù† Ø³Ø¨Ú© Ùˆ Ø³Ø±ÛŒØ¹")
root.geometry("700x600")
root.config(bg="#D7DBDD")

tk.Label(root, text="Ø¬Ù…Ù„Ù‡ Ø®ÙˆØ¯ Ø±Ø§ ÙˆØ§Ø±Ø¯ Ú©Ù†ÛŒØ¯ (ÙØ§Ø±Ø³ÛŒ ÛŒØ§ Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ):", bg="#D7DBDD").pack(pady=5)

text_entry = tk.Entry(root, width=85)
text_entry.pack(pady=5)
root.bind('<Return>', lambda event: detect_sentiment())

tk.Button(root, text="Ø§Ø±Ø³Ø§Ù„ Ø¬Ù…Ù„Ù‡ Ùˆ Ø¯Ø±ÛŒØ§ÙØª Ù¾Ø§Ø³Ø®", command=detect_sentiment).pack(pady=5)
tk.Button(root, text="Ù†Ù…Ø§ÛŒØ´ Ù†Ù…ÙˆØ¯Ø§Ø± Ø§Ø­Ø³Ø§Ø³Ø§Øª", command=show_chart).pack(pady=5)

conversation_text = tk.Text(root, width=85, height=25)
conversation_text.pack(pady=5)

root.mainloop()